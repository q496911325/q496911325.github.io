<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" /> -->
  
  
  <meta name="description" content="王鹏的博客" />
  

  
  <meta name="keywords" content="博客,王鹏,王鹏的博客,大数据,hadoop" />
  
  
  
  
  
  
  <title>王鹏</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="王鹏的博客">
<meta name="keywords" content="博客,王鹏,王鹏的博客,大数据,hadoop">
<meta property="og:type" content="website">
<meta property="og:title" content="王鹏">
<meta property="og:url" content="https:&#x2F;&#x2F;wpblog.top&#x2F;index.html">
<meta property="og:site_name" content="王鹏">
<meta property="og:description" content="王鹏的博客">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
  
  
    <link rel="icon" href="css/images/f1.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
  <!--<script src='//push.zhanzhang.baidu.com/push.js'></script>-->
</head>
<body class="home blog custom-background custom-font-enabled single-author">
  <div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="王鹏" rel="home">王鹏</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">每个人心中都有一个桃花源，找准方向，无畏前行，终有一天我们会到达。</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">主页</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives">文章</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/tags">标签</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/categories">分类</a></li>
                
                </ul>
            </div>
    </nav>
</header>

      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main">
  
    <article id="post-9200-hadoop" class="post-9200-hadoop post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/9200/">hadoop生态</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/9200/" data-id="ckc4ip28a000niwtv82oph9nx" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h3 id="一-Common"><a href="#一-Common" class="headerlink" title="一. Common"></a>一. Common</h3><p>包括Hadoop常用的工具类，由原来的Hadoop core部分更名而来。主要包括系统配置工具Configuration、远程过程调用RPC、序列化机制和Hadoop抽象文件系统FileSystem等。它们为在通用硬件上搭建云计算环境提供基本的服务，并为运行在该平台上的软件开发提供了所需的API</p>
<h3 id="二-HDFS"><a href="#二-HDFS" class="headerlink" title="二. HDFS"></a>二. HDFS</h3><h3 id="三-MapReduce"><a href="#三-MapReduce" class="headerlink" title="三. MapReduce"></a>三. MapReduce</h3><h3 id="四-YARN"><a href="#四-YARN" class="headerlink" title="四. YARN"></a>四. YARN</h3><h3 id="五-Hive-Pig-Shark"><a href="#五-Hive-Pig-Shark" class="headerlink" title="五. Hive(Pig/Shark)"></a>五. Hive(Pig/Shark)</h3><h3 id="六-HBase"><a href="#六-HBase" class="headerlink" title="六. HBase"></a>六. HBase</h3><h3 id="七-Zookeeper"><a href="#七-Zookeeper" class="headerlink" title="七. Zookeeper"></a>七. Zookeeper</h3><h3 id="八-Sqoop"><a href="#八-Sqoop" class="headerlink" title="八. Sqoop"></a>八. Sqoop</h3><h3 id="九-Flume"><a href="#九-Flume" class="headerlink" title="九. Flume"></a>九. Flume</h3><h3 id="十-Oozie"><a href="#十-Oozie" class="headerlink" title="十. Oozie"></a>十. Oozie</h3><h3 id="十一-Spark"><a href="#十一-Spark" class="headerlink" title="十一. Spark"></a>十一. Spark</h3>
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/9200/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">读书笔记</a></li></ul>

    </footer>
</article>






  
    <article id="post-1006-Hadoop环境搭建-首页" class="post-1006-Hadoop环境搭建-首页 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/1006/">Hadoop环境搭建-首页</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/1006/" data-id="ckc4ip27c0000iwtv3rgv8w58" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>原文地址：<a href="https://gitbook.cn/books/5954c9600326c7705af8a92a/index.html" target="_blank" rel="noopener">https://gitbook.cn/books/5954c9600326c7705af8a92a/index.html</a>  (需要付费)<br>                 <a href="https://blog.csdn.net/hliq5399/article/details/78193113" target="_blank" rel="noopener">https://blog.csdn.net/hliq5399/article/details/78193113</a>  (免费，内容和上面一样)</p>
<p>软件版本：<br>hadoop：2.5.0<br>jdk：1.7.0_67<br>linux：CentOS 6.6 64位<br>远程管理工具：Xmanager Enterprise 5</p>
<p>软件下载：<a href="https://pan.baidu.com/s/1h0np0XBZwUYXwmHILuqnjQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1h0np0XBZwUYXwmHILuqnjQ</a>  提取码：vt6h </p>
<p>PS：博主按照原文做了几遍，也踩过几个坑，原文作者是把几个部署方式写在一个环境里面的，第一次做看着会很混乱，所以我把每个步骤都独立开了，并且作者有些略过的地方我也根据自己的实践进行了补充。</p>
<h1>前言</h1>

<p>Hadoop在大数据技术体系中的地位至关重要，Hadoop是大数据技术的基础，对Hadoop基础知识的掌握的扎实程度，会决定在大数据技术道路上走多远。</p>
<p>这是一篇入门文章，Hadoop的学习方法很多，网上也有很多学习路线图。本文的思路是：以安装部署Apache Hadoop2.x版本为主线，来介绍Hadoop2.x的架构组成、各模块协同工作原理、技术细节。安装不是目的，通过安装认识Hadoop才是目的。</p>
<p>Hadoop部署模式有：本地模式、伪分布模式、完全分布式模式、HA完全分布式模式。</p>
<p>区分的依据是NameNode、DataNode、ResourceManager、NodeManager等模块运行在几个JVM进程、几个机器。</p>
<table border="1">
 <tr><th>模式名称</th><th>各个模块占用的JVM进程数</th><th>各个模块运行在几个机器数上</th></tr>
 <tr><td>本地模式</td><td>1个</td><td>1个</td></tr>
 <tr><td>伪分布式模式</td><td>N个</td><td>1个</td></tr>
 <tr><td>完全分布式模式</td><td>N个</td><td>N个</td></tr>
 <tr><td>HA完全分布式</td><td>N个</td><td>N个</td></tr>
</table>

<p>本文分为五个部分：</p>
<p>第一部分：<a href="/categories/hadoop/1007/">Linux环境安装</a><br>Hadoop是运行在Linux，虽然借助工具也可以运行在Windows上，但是建议还是运行在Linux系统上，第一部分介绍Linux环境的安装、配置、Java JDK安装等。</p>
<p>第二部分：<a href="/categories/hadoop/1008/">Hadoop本地模式安装</a><br>Hadoop本地模式只是用于本地开发调试，或者快速安装体验Hadoop，这部分做简单的介绍。</p>
<p>第三部分：<a href="/categories/hadoop/1009/">Hadoop伪分布式模式安装</a><br>学习Hadoop一般是在伪分布式模式下进行。这种模式是在一台机器上各个进程上运行Hadoop的各个模块，伪分布式的意思是虽然各个模块是在各个进程上分开运行的，但是只是运行在一个操作系统上的，并不是真正的分布式。</p>
<p>第四部分：<a href="/categories/hadoop/1010/">完全分布式安装</a><br>完全分布式模式才是生产环境采用的模式，Hadoop运行在服务器集群上，生产环境一般都会做HA，以实现高可用。</p>
<p>第五部分：<a href="/categories/hadoop/1011/">Hadoop HA安装</a><br>HA是指高可用，为了解决Hadoop单点故障问题，生产环境一般都做HA部署。这部分介绍了如何配置Hadoop2.x的高可用，并简单介绍了HA的工作原理。 安装过程中，会穿插简单介绍涉及到的知识。希望能对大家有所帮助</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/1006/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
</article>






  
    <article id="post-1010-Hadoop环境搭建-第四部分 完全分布式模式安装" class="post-1010-Hadoop环境搭建-第四部分 完全分布式模式安装 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/1010/">Hadoop环境搭建-第四部分 完全分布式模式安装</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/1010/" data-id="ckc4ip27z0007iwtv27iif046" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页：<a href="/categories/hadoop/1006/">Hadoop环境搭建</a></p>
<h2 id="第一部分、linux环境安装"><a href="#第一部分、linux环境安装" class="headerlink" title="第一部分、linux环境安装"></a>第一部分、linux环境安装</h2><h3 id="第一步、配置Vmware-NAT网络"><a href="#第一步、配置Vmware-NAT网络" class="headerlink" title="第一步、配置Vmware NAT网络"></a>第一步、配置Vmware NAT网络</h3><h4 id="一、Vmware网络模式介绍"><a href="#一、Vmware网络模式介绍" class="headerlink" title="一、Vmware网络模式介绍"></a>一、Vmware网络模式介绍</h4><p>参考：<a href="https://blog.csdn.net/collection4u/article/details/14127671" target="_blank" rel="noopener">https://blog.csdn.net/collection4u/article/details/14127671</a></p>
<h4 id="二、NAT模式配置"><a href="#二、NAT模式配置" class="headerlink" title="二、NAT模式配置"></a>二、NAT模式配置</h4><h5 id="1、aabbc"><a href="#1、aabbc" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim</span><br></pre></td></tr></table></figure>
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/1010/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
</article>






  
    <article id="post-9001-部署虚拟环境安装linux系统" class="post-9001-部署虚拟环境安装linux系统 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/linux/9001/">第一章：部署虚拟环境安装linux系统</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/linux/9001/" data-id="ckc4ip280000aiwtvcu5q0zcl" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页路径：<a href="/categories/linux/9000/">linux就该这么学</a></p>
<h3 id="一-重置root管理员密码"><a href="#一-重置root管理员密码" class="headerlink" title="一. 重置root管理员密码"></a>一. 重置root管理员密码</h3><ol>
<li>查询系统版本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/redhat-release</span><br></pre></td></tr></table></figure></li>
<li>reboot重启主机，出现引导界面时按下e键进入内核编辑界面</li>
<li>在linux16这行参数的最后面追加rd.break，然后按下ctrl+X组合键来运行修改过的内核程序。</li>
<li>依次输入一下命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mount -o remount,rw /sysroot</span><br><span class="line">chroot /sysroot</span><br><span class="line">passwd</span><br><span class="line"><span class="comment"># 这里输入新的root密码</span></span><br><span class="line"><span class="comment"># 这里再输入一次</span></span><br><span class="line">touch /.autorelabel</span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="二-rpm软件包管理器"><a href="#二-rpm软件包管理器" class="headerlink" title="二. rpm软件包管理器"></a>二. rpm软件包管理器</h3><table border="1">
  <tr><th>命令</th><th>描述</th></tr>
  <tr><td>rpm -ivh filename.rpm</td><td>安装软件的命令格式</td></tr>
  <tr><td>rpm -Uvh filename.rpm</td><td>升级软件的命令格式</td></tr>
  <tr><td>rpm -e filename.rpm</td><td>卸载软件的命令格式</td></tr>
  <tr><td>rpm -qpi filename.rpm</td><td>查询软件描述信息的命令格式</td></tr>
  <tr><td>rpm -qpl filename.rpm</td><td>列出软件文件信息的命令格式</td></tr>
  <tr><td>rpm -qf filename</td><td></td>查询文件属于哪个RPM的命令格式</tr>
  <tr><td>rpm -qa </td><td>列出所有安装过的包</td></tr>
  <tr><td>rpm -qa | grep sql</td><td>列出包含指定sql的包</td></tr>
</table>

<h3 id="三-yum软件仓库"><a href="#三-yum软件仓库" class="headerlink" title="三. yum软件仓库"></a>三. yum软件仓库</h3><table border="1">
  <tr><th>命令</th><th>描述</th></tr>
  <tr><td>yum repolist all</td><td>列出所有仓库</td></tr>
  <tr><td>yum list all</td><td>列出仓库中所有软件包</td></tr>
  <tr><td>yum info 软件包名称</td><td>查看软件包信息</td></tr>
  <tr><td>yum install 软件包名称</td><td>安装软件包</td></tr>
  <tr><td>yum reinstall 软件包名称</td><td>重新安装软件包</td></tr>
  <tr><td>yum update 软件包名称</td><td>升级软件包</td></tr>
  <tr><td>yum remove 软件包名称</td><td>移除软件包</td></tr>
  <tr><td>yum clean all </td><td>清除所有仓库缓存</td></tr>
  <tr><td>yum check-update </td><td>检查可更新的软件包</td></tr>
  <tr><td>yum grouplist</td><td>查看系统中已经安装的软件包组</td></tr>
  <tr><td>yum groupinstall 软件包组</td><td>安装指定的软件包组</td></tr>
  <tr><td>yum groupremove 软件包组</td><td>移除指定的软件包组</td></tr>
  <tr><td>yum groupinfo 软件包组</td><td>查询指定的软件包组信息</td></tr>
</table>

<h3 id="四-systemd初始化进程"><a href="#四-systemd初始化进程" class="headerlink" title="四. systemd初始化进程"></a>四. systemd初始化进程</h3><ol>
<li><p>systemd与System V init的区别以及作用</p>
<table border="1">
<tr><th>System V init运行级别</th><th>systemd目录名称</th><th>作用</th></tr>
<tr><td>0</td><td>runlevel0</td><td>关机</td></tr>
<tr><td>1</td><td>runlevel1</td><td>单用户模式</td></tr>
<tr><td>2</td><td>runlevel2</td><td>等同于级别3</td></tr>
<tr><td>3</td><td>runlevel3</td><td>多用户的文本界面</td></tr>
<tr><td>4</td><td>runlevel4</td><td>等同于级别3</td></tr>
<tr><td>5</td><td>runlevel5</td><td>多用户的图形界面</td></tr>
<tr><td>6</td><td>runlevel6</td><td>重启</td></tr>
<tr><td>emergency</td><td>emergency.target</td><td>紧急Shell</td></tr>
</table>
</li>
<li><p>systemctl管理服务的启动、重启、停止、重载、查看状态等常用命令</p>
<table border="1">
<tr><th>System V init命令</th><th>systemctl命令</th><th>作用</th></tr>
<tr><td>service foo start</td><td>systemctl start foo.service</td><td>启动服务</td></tr>
<tr><td>service foo restart</td><td>systemctl restart foo.service</td><td>重启服务</td></tr>
<tr><td>service foo stop</td><td>systemctl stop foo.service</td><td>停止服务</td></tr>
<tr><td>service foo reload</td><td>systemctl reload foo.service</td><td>重新加载配置文件(不终止服务)</td></tr>
<tr><td>service foo status</td><td>systemctl status foo.service</td><td>查看服务状态</td></tr>
</table>
</li>
<li><p>systemctl设置服务开机启动、不启动、查看各级别下服务启动状态等常用命令</p>
<table border="1">
<tr><th>System V init命令</th><th>systemctl命令</th><th>作用</th></tr>
<tr><td>chkconfig foo on</td><td>systemctl enable foo.service</td><td>开机自动启动</td></tr>
<tr><td>chkconfig foo off</td><td>systemctl disable foo.service</td><td>开机不自动启动</td></tr>
<tr><td>chkconfig foo</td><td>systemctl is-enable foo.service</td><td>查看特定服务是否为开机自动启动</td></tr>
<tr><td>chkconfig --list</td><td>systemctl list-unit-files --type=service</td><td>查看各个级别下服务的启动和禁用情况</td></tr>
</table>
</li>
</ol>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/linux/9001/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

    
    </footer>
</article>






  
    <article id="post-1011-Hadoop环境搭建-第五部分 Hadoop HA安装" class="post-1011-Hadoop环境搭建-第五部分 Hadoop HA安装 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/1011/">Hadoop环境搭建-第五部分 Hadoop HA安装</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/1011/" data-id="ckc4ip282000ciwtv1tql0yxu" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页：<a href="/categories/hadoop/1006/">Hadoop环境搭建</a></p>
<h2 id="第五部分、Hadoop-HA安装"><a href="#第五部分、Hadoop-HA安装" class="headerlink" title="第五部分、Hadoop HA安装"></a>第五部分、Hadoop HA安装</h2><h3 id="第一步、环境配置"><a href="#第一步、环境配置" class="headerlink" title="第一步、环境配置"></a>第一步、环境配置</h3><h4 id="一、配置网络"><a href="#一、配置网络" class="headerlink" title="一、配置网络"></a>一、配置网络</h4><h5 id="1、aabbc"><a href="#1、aabbc" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><h5 id="1、aabbc-1"><a href="#1、aabbc-1" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><h4 id="二、"><a href="#二、" class="headerlink" title="二、"></a>二、</h4><h5 id="1、aabbc-2"><a href="#1、aabbc-2" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim</span><br></pre></td></tr></table></figure>

<h4 id="二、-1"><a href="#二、-1" class="headerlink" title="二、"></a>二、</h4><h5 id="1、aabbc-3"><a href="#1、aabbc-3" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim</span><br></pre></td></tr></table></figure>

<h4 id="二、-2"><a href="#二、-2" class="headerlink" title="二、"></a>二、</h4><h5 id="1、aabbc-4"><a href="#1、aabbc-4" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim</span><br></pre></td></tr></table></figure>

<h4 id="二、-3"><a href="#二、-3" class="headerlink" title="二、"></a>二、</h4><h5 id="1、aabbc-5"><a href="#1、aabbc-5" class="headerlink" title="1、aabbc"></a>1、aabbc</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim</span><br></pre></td></tr></table></figure>
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/1011/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
</article>






  
    <article id="post-9004-Vim编辑器与Shell命令脚本" class="post-9004-Vim编辑器与Shell命令脚本 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/linux/9004/">第四章：Vim编辑器与Shell命令脚本</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/linux/9004/" data-id="ckc4ip284000fiwtv07js0vtq" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页路径：<a href="/categories/linux/9000/">linux就该这么学</a></p>
<h3 id="一-Vim文本编辑器"><a href="#一-Vim文本编辑器" class="headerlink" title="一. Vim文本编辑器"></a>一. Vim文本编辑器</h3><ol>
<li><p>三种模式<br>命令模式：控制光标移动，可对文本进行复制、粘贴、删除和查找等工作<br>输入模式：正常的文本录入<br>末行模式：保存或退出文档，以及设置编辑环境</p>
</li>
<li><p>命令模式中常用命令</p>
<table border="1">
<tr><th>命令</th><th>作用</th></tr>
<tr><td>dd</td><td>删除(剪切)光标所在整行</td></tr>
<tr><td>5dd</td><td>删除(剪切)从光标处开始的5行</td></tr>
<tr><td>yy</td><td>复制光标所在整行</td></tr>
<tr><td>5yy></td><td>复制从光标处开始的5行</td></tr>
<tr><td>n</td><td>显示搜索命令定位到的下一个字符串</td></tr>
<tr><td>N</td><td>显示搜索命令定位到的上一个字符串</td></tr>
<tr><td>u</td><td>撤销上一步的操作</td></tr>
<tr><td>p</td><td>将之前删除或复制过得数据粘贴到光标后面</td></tr>
</table>
</li>
<li><p>末行模式中可用的命令</p>
<table border="1">
<tr><th>命令</th><th>作用</th></tr>
<tr><td>:w</td><td>保存</td></tr>
<tr><td>:q</td><td>退出</td></tr>
<tr><td>:q!</td><td>强制退出(放弃对文档的修改内容)</td></tr>
<tr><td>:wq!</td><td>强制保存退出</td></tr>
<tr><td>set nu</td><td>显示行号</td></tr>
<tr><td>set nonu</td><td>不显示行号</td></tr>
<tr><td>:命令</td><td>执行该命令</td></tr>
<tr><td>:整数</td><td>跳转到该行</td></tr>
<tr><td>:s/one/two</td><td>将当前光标所在行的第一个one替换成two</td></tr>
<tr><td>:s/one/two/g</td><td>将当前光标所在行的所有one替换成two</td></tr>
<tr><td>:%s/one/two/g</td><td>将全文中的所有one替换成two</td></tr>
<tr><td>?字符串</td><td>在文本中从下至上搜索该字符串</td></tr>
<tr><td>/字符串</td><td>在文本中从上至下搜索该字符串</td></tr>
</table>

</li>
</ol>
<h3 id="二-配置主机名称"><a href="#二-配置主机名称" class="headerlink" title="二. 配置主机名称"></a>二. 配置主机名称</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure>

<h3 id="三-配置网卡信息"><a href="#三-配置网卡信息" class="headerlink" title="三. 配置网卡信息"></a>三. 配置网卡信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-enoxxxxxx</span><br><span class="line"></span><br><span class="line">设备类型：TYPE=Ethernet</span><br><span class="line">地址分配模式：BOOTPROTO=static</span><br><span class="line">网卡名称：NAME=eno16777736</span><br><span class="line">是否启动：ONBOOT=yes</span><br><span class="line">IP地址：IPADDR=192.168.10.10</span><br><span class="line">子网掩码：NETMASK=255.255.255.0</span><br><span class="line">网关地址：GATEWAY=192.168.10.1</span><br><span class="line">DNS地址：DNS1=192.168.10.1</span><br><span class="line"></span><br><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure>

<h3 id="四-配置Yum软件仓库"><a href="#四-配置Yum软件仓库" class="headerlink" title="四. 配置Yum软件仓库"></a>四. 配置Yum软件仓库</h3><h3 id="五-编写SHELL脚本"><a href="#五-编写SHELL脚本" class="headerlink" title="五. 编写SHELL脚本"></a>五. 编写SHELL脚本</h3><h4 id="1-接收用户的参数"><a href="#1-接收用户的参数" class="headerlink" title="1. 接收用户的参数"></a>1. 接收用户的参数</h4><table border="1">
  <tr><th>命令</th><th>作用</th></tr>
  <tr><td>$0</td><td>当前shell脚本程序的名称</td></tr>
  <tr><td>$#</td><td>总共有几个参数</td></tr>
  <tr><td>$*</td><td>所有位置的参数值</td></tr>
  <tr><td>$?</td><td>显示上一次命令的执行返回值 0表示没有错误 其他任何值表明有错误</td></tr>
  <tr><td>$n</td><td>n=1...9</td></tr>
  <tr><td>$$</td><td>这个脚本程序的PID</td></tr>
  <tr><td>$@</td><td>跟$*类似，但是可以当作数组用</td></tr>
</table>

<h4 id="2-判断用户的参数"><a href="#2-判断用户的参数" class="headerlink" title="2. 判断用户的参数"></a>2. 判断用户的参数</h4><ol>
<li><p>文件测试语句</p>
<table border="1">
<tr><th>命令</th><th>作用</th></tr>
<tr><td>-d</td><td>测试文件是否为目录类型</td></tr>
<tr><td>-e</td><td>测试文件是否存在</td></tr>
<tr><td>-f</td><td>判断是否为一般文件</td></tr>
<tr><td>-r</td><td>测试当前用户是否有权限读取</td></tr>
<tr><td>-w</td><td>测试当前用户是否有权限写入</td></tr>
<tr><td>-x</td><td>测试当前用户是否有权限执行</td></tr>
</table>
</li>
<li><p>逻辑测试语句</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&amp;&amp; 前面命令执行成功才会执行后面的命令</span><br><span class="line">|| 前面命令执行失败才会执行后面的命令</span><br><span class="line">! 得到的值取反</span><br><span class="line">[ -e /opt/aa ] &amp;&amp; <span class="built_in">echo</span> <span class="string">"true"</span> || <span class="built_in">echo</span> <span class="string">"false"</span></span><br><span class="line">[ ! -e /opt/aa ] &amp;&amp; <span class="built_in">echo</span> <span class="string">"true"</span> || <span class="built_in">echo</span> <span class="string">"false"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>整数值比较语句</p>
<table border="1">
<tr><th>运算符</th><th>作用</th></tr>
<tr><td>-eq</td><td>是否等于</td></tr>
<tr><td>-ne</td><td>是否不等于</td></tr>
<tr><td>-gt</td><td>是否大于</td></tr>
<tr><td>-lt</td><td>是否小于</td></tr>
<tr><td>-le</td><td>是否等于或小于</td></tr>
<tr><td>-ge</td><td>是否大于或小于</td></tr>
</table>
</li>
<li><p>字符串比较语句</p>
<table border="1">
<tr><th>运算符</th><th>作用</th></tr>
<tr><td>=</td><td>比较字符串内容是否相同</td></tr>
<tr><td>!=</td><td>比较字符串内容是否不同</td></tr>
<tr><td>-z</td><td>判断字符串是否为空</td></tr>
</table>

</li>
</ol>
<h4 id="3-流程控制语句-if-for-while-case"><a href="#3-流程控制语句-if-for-while-case" class="headerlink" title="3. 流程控制语句(if for while case)"></a>3. 流程控制语句(if for while case)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ 条件1 ] ; <span class="keyword">then</span></span><br><span class="line">	代码块</span><br><span class="line"><span class="keyword">elif</span> [ 条件1 ]  ; <span class="keyword">then</span></span><br><span class="line">	代码块</span><br><span class="line"><span class="keyword">else</span> </span><br><span class="line">	代码块</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">-----------------------------------------------------------</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> UNAME <span class="keyword">in</span> `cat users.txt`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="variable">$UNAME</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">-----------------------------------------------------------</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">TIMES=0</span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$TIMES</span> -eq 10 ] ; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$TIMES</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">let</span> TIMES++</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">-----------------------------------------------------------</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">read</span> -p <span class="string">"请输入一个字符，并按enter键结束："</span> KEY</span><br><span class="line"><span class="keyword">case</span> <span class="variable">$KEY</span> <span class="keyword">in</span></span><br><span class="line">[a-z]|[A-Z])</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"字母"</span></span><br><span class="line">;;</span><br><span class="line">[0-9])</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"数字"</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"其他"</span></span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<h3 id="六-计划任务服务程序"><a href="#六-计划任务服务程序" class="headerlink" title="六. 计划任务服务程序"></a>六. 计划任务服务程序</h3><ol>
<li><p>一次性计划任务<br>创建：echo “ls” | at 23:00<br>查看：at -l<br>删除：atrm 2</p>
</li>
<li><p>长期性计划任务<br>创建或编辑：crontab -e<br>查看：crontab -l<br>删除：crontab -r<br>管理员编辑其他用户的计划任务：crontab -u 用户名<br>查看日志：<br>cat /var/log/cron<br>cat /var/spool/mail/用户名</p>
</li>
</ol>
<p>分 时 日 月 星期 命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">* * * * * 命令</span><br></pre></td></tr></table></figure>
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/linux/9004/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

    
    </footer>
</article>






  
    <article id="post-1009-Hadoop环境搭建-第三部分 伪分布式模式安装" class="post-1009-Hadoop环境搭建-第三部分 伪分布式模式安装 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/1009/">Hadoop环境搭建-第三部分 伪分布式模式安装</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/1009/" data-id="ckc4ip286000iiwtv0wb38lrl" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页：<a href="/categories/hadoop/1006/">Hadoop环境搭建</a></p>
<h2 id="第一部分、Hadoop伪分布式模式安装"><a href="#第一部分、Hadoop伪分布式模式安装" class="headerlink" title="第一部分、Hadoop伪分布式模式安装"></a>第一部分、Hadoop伪分布式模式安装</h2><h3 id="第一步、伪分布式Hadoop部署过程"><a href="#第一步、伪分布式Hadoop部署过程" class="headerlink" title="第一步、伪分布式Hadoop部署过程"></a>第一步、伪分布式Hadoop部署过程</h3><h4 id="一、复制实验虚拟机-本地模式中有具体步骤，不再列出"><a href="#一、复制实验虚拟机-本地模式中有具体步骤，不再列出" class="headerlink" title="一、复制实验虚拟机(本地模式中有具体步骤，不再列出)"></a>一、复制实验虚拟机(本地模式中有具体步骤，不再列出)</h4><h4 id="二、重新配置实验机网络-本地模式中有具体步骤，不再列出"><a href="#二、重新配置实验机网络-本地模式中有具体步骤，不再列出" class="headerlink" title="二、重新配置实验机网络(本地模式中有具体步骤，不再列出)"></a>二、重新配置实验机网络(本地模式中有具体步骤，不再列出)</h4><p><a href="/categories/hadoop/1006/">Hadoop本地模式安装</a></p>
<h4 id="三、Hadoop所用的用户设置"><a href="#三、Hadoop所用的用户设置" class="headerlink" title="三、Hadoop所用的用户设置"></a>三、Hadoop所用的用户设置</h4><h5 id="1、创建一个名字为hadoop的普通用户"><a href="#1、创建一个名字为hadoop的普通用户" class="headerlink" title="1、创建一个名字为hadoop的普通用户"></a>1、创建一个名字为hadoop的普通用户</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># useradd hadoop</span></span><br><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># passwd hadoop</span></span><br></pre></td></tr></table></figure>

<h5 id="2、给hadoop用户sudo权限"><a href="#2、给hadoop用户sudo权限" class="headerlink" title="2、给hadoop用户sudo权限"></a>2、给hadoop用户sudo权限</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># vim /etc/sudoers</span></span><br></pre></td></tr></table></figure>

<p>设置权限，学习环境可以将hadoop用户的权限设置的大一些，但是生产环境一定要注意普通用户的权限限制。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root       ALL=(ALL)       ALL</span><br><span class="line">hadoop ALL=(root) NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>注意：如果root用户无权修改sudoers文件，先手动为root用户添加写权限。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># chmod u+w /etc/sudoers</span></span><br></pre></td></tr></table></figure>


<h5 id="3、切换到hadoop用户"><a href="#3、切换到hadoop用户" class="headerlink" title="3、切换到hadoop用户"></a>3、切换到hadoop用户</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># su - hadoop</span></span><br><span class="line">[hadoop@bigdata-senior01 ~]$</span><br></pre></td></tr></table></figure>

<h5 id="4、将hadoop文件夹的所有者指定为hadoop用户"><a href="#4、将hadoop文件夹的所有者指定为hadoop用户" class="headerlink" title="4、将hadoop文件夹的所有者指定为hadoop用户"></a>4、将hadoop文件夹的所有者指定为hadoop用户</h5><p>如果存放hadoop的目录的所有者不是hadoop，之后hadoop运行中可能会有权限问题，那么就讲所有者改为hadoop。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 ~]$ sudo chown -R hadoop:hadoop /opt/modules</span><br></pre></td></tr></table></figure>

<h4 id="四、解压Hadoop目录文件"><a href="#四、解压Hadoop目录文件" class="headerlink" title="四、解压Hadoop目录文件"></a>四、解压Hadoop目录文件</h4><h5 id="1、解压hadoop-2-5-0-tar-gz到-opt-modules目录下。"><a href="#1、解压hadoop-2-5-0-tar-gz到-opt-modules目录下。" class="headerlink" title="1、解压hadoop-2.5.0.tar.gz到/opt/modules目录下。"></a>1、解压hadoop-2.5.0.tar.gz到/opt/modules目录下。</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 ~]$ tar -zxvf /opt/hadoop-2.5.0.tar.gz -C /opt/modules/</span><br></pre></td></tr></table></figure>

<h4 id="二、配置Hadoop"><a href="#二、配置Hadoop" class="headerlink" title="二、配置Hadoop"></a>二、配置Hadoop</h4><h5 id="1、配置Hadoop环境变量"><a href="#1、配置Hadoop环境变量" class="headerlink" title="1、配置Hadoop环境变量"></a>1、配置Hadoop环境变量</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 ~]$ sudo vim /etc/profile</span><br></pre></td></tr></table></figure>

<p>追加配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=<span class="string">"/opt/modules/hadoop-2.5.0"</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>执行：source /etc/profile 使得配置生效</p>
<p>验证HADOOP_HOME参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 ~]$ <span class="built_in">echo</span> <span class="variable">$HADOOP_HOME</span></span><br></pre></td></tr></table></figure>

<h5 id="2、配置-hadoop-env-sh、mapred-env-sh、yarn-env-sh文件的JAVA-HOME参数"><a href="#2、配置-hadoop-env-sh、mapred-env-sh、yarn-env-sh文件的JAVA-HOME参数" class="headerlink" title="2、配置 hadoop-env.sh、mapred-env.sh、yarn-env.sh文件的JAVA_HOME参数"></a>2、配置 hadoop-env.sh、mapred-env.sh、yarn-env.sh文件的JAVA_HOME参数</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 ~]$ <span class="built_in">cd</span> /opt/modules/hadoop-2.5.0/</span><br><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo vim etc/hadoop/hadoop-env.sh</span><br><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo vim etc/hadoop/mapred-env.sh</span><br><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo vim etc/hadoop/yarn-env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">修改三个文件中的JAVA_HOME参数为：</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="string">"/opt/modules/jdk1.7.0_67"</span></span><br></pre></td></tr></table></figure>

<h5 id="3、配置core-site-xml"><a href="#3、配置core-site-xml" class="headerlink" title="3、配置core-site.xml"></a>3、配置core-site.xml</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo vim etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建/12-core.png">

<p>（1） fs.defaultFS参数配置的是HDFS的地址。</p>
<p>（2） hadoop.tmp.dir配置的是Hadoop临时目录，比如HDFS的NameNode数据默认都存放这个目录下，查看*-default.xml等默认配置文件，就可以看到很多依赖${hadoop.tmp.dir}的配置。</p>
<p>默认的hadoop.tmp.dir是/tmp/hadoop-${user.name},此时有个问题就是NameNode会将HDFS的元数据存储在这个/tmp目录下，如果操作系统重启了，系统会清空/tmp目录下的东西，导致NameNode元数据丢失，是个非常严重的问题，所有我们应该修改这个路径。</p>
<p>创建临时目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo mkdir -p /opt/data/tmp</span><br></pre></td></tr></table></figure>

<p>将临时目录的所有者修改为hadoop</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo chown -R hadoop:hadoop /opt/data/tmp</span><br></pre></td></tr></table></figure>

<h4 id="二、配置、格式化、启动HDFS"><a href="#二、配置、格式化、启动HDFS" class="headerlink" title="二、配置、格式化、启动HDFS"></a>二、配置、格式化、启动HDFS</h4><h5 id="1、配置hdfs-site-xml"><a href="#1、配置hdfs-site-xml" class="headerlink" title="1、配置hdfs-site.xml"></a>1、配置hdfs-site.xml</h5><img src="/css/images/hadoop环境搭建/13-hdfs.png">

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ vim etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure>

<p>dfs.replication配置的是HDFS存储时的备份数量，因为这里是伪分布式环境只有一个节点，所以这里设置为1。</p>
<h5 id="2、格式化HDFS"><a href="#2、格式化HDFS" class="headerlink" title="2、格式化HDFS"></a>2、格式化HDFS</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建/14-格式化.png">

<p>格式化是对HDFS这个分布式文件系统中的DataNode进行分块，统计所有分块后的初始元数据的存储在NameNode中。</p>
<p>格式化后，查看core-site.xml里hadoop.tmp.dir（本例是/opt/data目录）指定的目录下是否有了dfs目录，如果有，说明格式化成功。</p>
<p>注意：</p>
<p>(1) 格式化时，这里注意hadoop.tmp.dir目录的权限问题，应该hadoop普通用户有读写权限才行，可以将/opt/data的所有者改为hadoop。 [hadoop@bigdata-senior01 hadoop-2.5.0]$ sudo chown -R hadoop:hadoop /opt/data</p>
<p>(2) 查看NameNode格式化后的目录。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ ll /opt/data/tmp/dfs/name/current</span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建/15-current.png">

<p>fsimage是NameNode元数据在内存满了后，持久化保存到的文件。fsimage*.md5 是校验文件，用于校验fsimage的完整性。seen_txid 是hadoop的版本</p>
<p>vession文件里保存：</p>
<p>namespaceID：NameNode的唯一ID。</p>
<p>clusterID:集群ID，NameNode和DataNode的集群ID应该一致，表明是一个集群。</p>
<img src="/css/images/hadoop环境搭建/16-vession.png">

<h5 id="3、启动NameNode"><a href="#3、启动NameNode" class="headerlink" title="3、启动NameNode"></a>3、启动NameNode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line">starting namenode, logging to /opt/modules/hadoop-2.5.0/logs/hadoop-hadoop-namenode-bigdata-senior01.chybinmy.com.out</span><br></pre></td></tr></table></figure>

<h5 id="4、启动DataNode"><a href="#4、启动DataNode" class="headerlink" title="4、启动DataNode"></a>4、启动DataNode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">starting datanode, logging to /opt/modules/hadoop-2.5.0/logs/hadoop-hadoop-datanode-bigdata-senior01.chybinmy.com.out</span><br></pre></td></tr></table></figure>

<h5 id="5、启动SecondaryNameNode"><a href="#5、启动SecondaryNameNode" class="headerlink" title="5、启动SecondaryNameNode"></a>5、启动SecondaryNameNode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$ sbin/hadoop-daemon.sh start secondarynamenode</span><br><span class="line">starting secondarynamenode, logging to /opt/modules/hadoop-2.5.0/logs/hadoop-hadoop-secondarynamenode-bigdata-senior01.chybinmy.com.out</span><br></pre></td></tr></table></figure>

<h5 id="6、JPS命令查看是否已经启动成功，有结果就是启动成功了。"><a href="#6、JPS命令查看是否已经启动成功，有结果就是启动成功了。" class="headerlink" title="6、JPS命令查看是否已经启动成功，有结果就是启动成功了。"></a>6、JPS命令查看是否已经启动成功，有结果就是启动成功了。</h5><img src="/css/images/hadoop环境搭建/17-jps.png">

<h5 id="7、HDFS上测试创建目录、上传、下载文件"><a href="#7、HDFS上测试创建目录、上传、下载文件" class="headerlink" title="7、HDFS上测试创建目录、上传、下载文件"></a>7、HDFS上测试创建目录、上传、下载文件</h5><p>HDFS上创建目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$</span><br></pre></td></tr></table></figure>

<p>上传本地文件到HDFS上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$</span><br></pre></td></tr></table></figure>

<p>读取HDFS上的文件内容</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-senior01 hadoop-2.5.0]$</span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建/18-文件内容.png">

<p>从HDFS上下载文件到本地</p>
<h4 id="三、配置、启动YARN"><a href="#三、配置、启动YARN" class="headerlink" title="三、配置、启动YARN"></a>三、配置、启动YARN</h4><h5 id="1、配置mapred-site-xml"><a href="#1、配置mapred-site-xml" class="headerlink" title="1、配置mapred-site.xml"></a>1、配置mapred-site.xml</h5><h5 id="2、配置yarn-site-xml"><a href="#2、配置yarn-site-xml" class="headerlink" title="2、配置yarn-site.xml"></a>2、配置yarn-site.xml</h5><h5 id="3、启动Resourcemanager"><a href="#3、启动Resourcemanager" class="headerlink" title="3、启动Resourcemanager"></a>3、启动Resourcemanager</h5><h5 id="4、启动nodemanager"><a href="#4、启动nodemanager" class="headerlink" title="4、启动nodemanager"></a>4、启动nodemanager</h5><h5 id="5、查看是否启动成功"><a href="#5、查看是否启动成功" class="headerlink" title="5、查看是否启动成功"></a>5、查看是否启动成功</h5><h5 id="6、YARN的Web页面"><a href="#6、YARN的Web页面" class="headerlink" title="6、YARN的Web页面"></a>6、YARN的Web页面</h5><h4 id="四、运行MapReduce-Job"><a href="#四、运行MapReduce-Job" class="headerlink" title="四、运行MapReduce Job"></a>四、运行MapReduce Job</h4><h5 id="1、创建测试用的Input文件"><a href="#1、创建测试用的Input文件" class="headerlink" title="1、创建测试用的Input文件"></a>1、创建测试用的Input文件</h5><h5 id="2、运行WordCount-MapReduce-Job"><a href="#2、运行WordCount-MapReduce-Job" class="headerlink" title="2、运行WordCount MapReduce Job"></a>2、运行WordCount MapReduce Job</h5><h5 id="3、查看输出结果目录"><a href="#3、查看输出结果目录" class="headerlink" title="3、查看输出结果目录"></a>3、查看输出结果目录</h5><h4 id="五、停止Hadoop"><a href="#五、停止Hadoop" class="headerlink" title="五、停止Hadoop"></a>五、停止Hadoop</h4><h4 id="六、Hadoop各个功能模块的理解"><a href="#六、Hadoop各个功能模块的理解" class="headerlink" title="六、Hadoop各个功能模块的理解"></a>六、Hadoop各个功能模块的理解</h4><h5 id="1、HDFS模块"><a href="#1、HDFS模块" class="headerlink" title="1、HDFS模块"></a>1、HDFS模块</h5><h5 id="2、YARN模块"><a href="#2、YARN模块" class="headerlink" title="2、YARN模块"></a>2、YARN模块</h5><h5 id="3、MapReduce模块"><a href="#3、MapReduce模块" class="headerlink" title="3、MapReduce模块"></a>3、MapReduce模块</h5><h3 id="第二步、开启历史服务"><a href="#第二步、开启历史服务" class="headerlink" title="第二步、开启历史服务"></a>第二步、开启历史服务</h3><h4 id="一、历史服务介绍"><a href="#一、历史服务介绍" class="headerlink" title="一、历史服务介绍"></a>一、历史服务介绍</h4><h4 id="二、开启历史服务"><a href="#二、开启历史服务" class="headerlink" title="二、开启历史服务"></a>二、开启历史服务</h4><h4 id="三、Web查看job执行历史"><a href="#三、Web查看job执行历史" class="headerlink" title="三、Web查看job执行历史"></a>三、Web查看job执行历史</h4><h4 id="四、历史服务介绍"><a href="#四、历史服务介绍" class="headerlink" title="四、历史服务介绍"></a>四、历史服务介绍</h4><h5 id="1、运行一个mapreduce任务"><a href="#1、运行一个mapreduce任务" class="headerlink" title="1、运行一个mapreduce任务"></a>1、运行一个mapreduce任务</h5><h5 id="2、job执行中"><a href="#2、job执行中" class="headerlink" title="2、job执行中"></a>2、job执行中</h5><h5 id="3、查看job历史"><a href="#3、查看job历史" class="headerlink" title="3、查看job历史"></a>3、查看job历史</h5><h4 id="四、开启日志聚集"><a href="#四、开启日志聚集" class="headerlink" title="四、开启日志聚集"></a>四、开启日志聚集</h4><h5 id="1、日志聚集介绍"><a href="#1、日志聚集介绍" class="headerlink" title="1、日志聚集介绍"></a>1、日志聚集介绍</h5><h5 id="2、开启日志聚集"><a href="#2、开启日志聚集" class="headerlink" title="2、开启日志聚集"></a>2、开启日志聚集</h5><h5 id="3、测试日志聚集"><a href="#3、测试日志聚集" class="headerlink" title="3、测试日志聚集"></a>3、测试日志聚集</h5>
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/1009/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
</article>






  
    <article id="post-9000-linux就该这么学" class="post-9000-linux就该这么学 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/linux/9000/">linux就该这么学</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/linux/9000/" data-id="ckc4ip288000jiwtv7q8a1qns" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>第一章：<a href="/categories/linux/9001/">部署虚拟环境安装linux系统</a><br>第二章：<a href="/categories/linux/9002/">新手必须掌握的Linux命令</a><br>第三章：<a href="/categories/linux/9003/">管道符、重定向与环境变量</a><br>第四章：<a href="/categories/linux/9004/">Vim编辑器与Shell命令脚本</a><br>第五章：<a href="/categories/linux/9005/">用户身份与文件权限</a><br>第六章：<a href="/categories/linux/9006/">存储结构与硬盘划分</a><br>第七章：<a href="/categories/linux/9007/">使用RAID与LVM磁盘阵列技术</a><br>第八章：<a href="/categories/linux/9008/">iptables与firewalld防火墙</a><br>第九章：<a href="/categories/linux/9009/">使用ssh服务管理远程主机</a><br>第十章：<a href="/categories/linux/9010/">使用Apache服务部署静态网站</a><br>第十一章：<a href="/categories/linux/9011/">使用vsftpd服务传输文件</a><br>第十二章：<a href="/categories/linux/9012/">使用Samba或NFS实现文件共享</a><br>第十三章：<a href="/categories/linux/9013/">使用BIND提供域名解析服务</a><br>第十四章：<a href="/categories/linux/9014/">使用DHCP动态管理主机地址</a><br>第十五章：<a href="/categories/linux/9015/">使用Postfix与Dovecot部署邮件系统</a><br>第十六章：<a href="/categories/linux/9016/">使用Squid部署代理缓存服务</a><br>第十七章：<a href="/categories/linux/9017/">使用iSCSI服务部署网络存储</a><br>第十八章：<a href="/categories/linux/9018/">使用MariaDB数据库管理系统</a><br>第十九章：<a href="/categories/linux/9019/">使用PXE+Kickstart无人值守安装服务</a><br>第二十章：<a href="/categories/linux/9020/">使用LNMP架构部署动态网站环境</a></p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/linux/9000/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/linux/">linux</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">读书笔记</a></li></ul>

    </footer>
</article>






  
    <article id="post-1008-Hadoop环境搭建-第二部分 本地模式安装" class="post-1008-Hadoop环境搭建-第二部分 本地模式安装 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/1008/">Hadoop环境搭建-第二部分 Hadoop本地模式安装</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/1008/" data-id="ckc4ip27x0005iwtv89pu8az9" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <p>本系列首页：<a href="/categories/hadoop/1006/">Hadoop环境搭建</a></p>
<h2 id="第二部分、Hadoop本地模式安装"><a href="#第二部分、Hadoop本地模式安装" class="headerlink" title="第二部分、Hadoop本地模式安装"></a>第二部分、Hadoop本地模式安装</h2><h3 id="第一步、本地模式部署"><a href="#第一步、本地模式部署" class="headerlink" title="第一步、本地模式部署"></a>第一步、本地模式部署</h3><h4 id="一、复制实验虚拟机-两种方法-任选一种就好"><a href="#一、复制实验虚拟机-两种方法-任选一种就好" class="headerlink" title="一、复制实验虚拟机(两种方法 任选一种就好)"></a>一、复制实验虚拟机(两种方法 任选一种就好)</h4><h5 id="1、克隆"><a href="#1、克隆" class="headerlink" title="1、克隆"></a>1、克隆</h5><p>右键模板系统model-管理-克隆，进入克隆虚拟机向导</p>
<img src="/css/images/hadoop环境搭建1/1-欢迎.png">
<img src="/css/images/hadoop环境搭建1/2-克隆源.png">
<img src="/css/images/hadoop环境搭建1/3-类型.png">
<img src="/css/images/hadoop环境搭建1/4-名称.png">

<h5 id="2、复制"><a href="#2、复制" class="headerlink" title="2、复制"></a>2、复制</h5><p>找到model文件夹，ctrl+c复制整个文件夹，ctrl+v粘贴，修改新的文件夹名为BigData01，并进入文件打开model.vmx</p>
<img src="/css/images/hadoop环境搭建1/5-复制.png">
<img src="/css/images/hadoop环境搭建1/6-打开.png">

<p>重命名虚拟机中新打开的model为BigData01，开启此虚拟机，选择我已复制虚拟机</p>
<img src="/css/images/hadoop环境搭建1/7-虚拟机.png">
<img src="/css/images/hadoop环境搭建1/7-复制虚拟机.png">

<h4 id="二、重新配置实验机网络"><a href="#二、重新配置实验机网络" class="headerlink" title="二、重新配置实验机网络"></a>二、重新配置实验机网络</h4><p>修改网卡名称：</p>
<p>在BigData01机器上编辑网卡信息。执行vim /etc/udev/rules.d/70-persistent-net.rules命令。因为是从model机器克隆来的，所以会保留model的网卡eth0，并且再添加一个网卡eth1。并且eth0的Mac地址和model的地址是一样的，Mac地址不允许相同，所以要删除eth0，只保留eth1网卡，并且要将eth1改名为eth0。将修改后的eth0的mac地址复制下来，修改network-scripts文件中的HWADDR属性。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># vim /etc/sysconfig/network-scripts/ifcfg-eth0</span></span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建1/8-HWADDR.png">

<p>修改完成后reboot重启，再查看网卡信息，只剩下了eth0，配置完成。</p>
<img src="/css/images/hadoop环境搭建1/9-Edit.png">
<img src="/css/images/hadoop环境搭建1/10-网卡.png">


<h4 id="三、本地模式介绍"><a href="#三、本地模式介绍" class="headerlink" title="三、本地模式介绍"></a>三、本地模式介绍</h4><p>本地模式是最简单的模式，所有模块都运行与一个JVM进程中，使用的本地文件系统，而不是HDFS，本地模式主要是用于本地开发过程中的运行调试用。下载hadoop安装包后不用任何设置，默认的就是本地模式。</p>
<h4 id="四、解压hadoop后就是直接可以使用"><a href="#四、解压hadoop后就是直接可以使用" class="headerlink" title="四、解压hadoop后就是直接可以使用"></a>四、解压hadoop后就是直接可以使用</h4><h5 id="1、创建一个存放本地模式hadoop的目录"><a href="#1、创建一个存放本地模式hadoop的目录" class="headerlink" title="1、创建一个存放本地模式hadoop的目录"></a>1、创建一个存放本地模式hadoop的目录</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># mkdir /opt/modules/hadoopstandalone</span></span><br></pre></td></tr></table></figure>

<h5 id="2、解压hadoop文件"><a href="#2、解压hadoop文件" class="headerlink" title="2、解压hadoop文件"></a>2、解压hadoop文件</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># tar -zxvf /opt/hadoop-2.5.0.tar.gz  -C /opt/modules/hadoopstandalone/</span></span><br></pre></td></tr></table></figure>

<h5 id="3、确保JAVA-HOME环境变量已经配置好"><a href="#3、确保JAVA-HOME环境变量已经配置好" class="headerlink" title="3、确保JAVA_HOME环境变量已经配置好"></a>3、确保JAVA_HOME环境变量已经配置好</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># echo $&#123;JAVA_HOME&#125;</span></span><br><span class="line">/opt/modules/jdk1.7.0_67</span><br></pre></td></tr></table></figure>

<h4 id="五、运行MapReduce程序，验证"><a href="#五、运行MapReduce程序，验证" class="headerlink" title="五、运行MapReduce程序，验证"></a>五、运行MapReduce程序，验证</h4><p>我们这里用hadoop自带的wordcount例子来在本地模式下测试跑mapreduce。</p>
<h5 id="1、准备mapreduce输入文件wc-input-cat写完保存可以用ctrl-d，写完可以用vim检查一下"><a href="#1、准备mapreduce输入文件wc-input-cat写完保存可以用ctrl-d，写完可以用vim检查一下" class="headerlink" title="1、准备mapreduce输入文件wc.input(cat写完保存可以用ctrl+d，写完可以用vim检查一下)"></a>1、准备mapreduce输入文件wc.input(cat写完保存可以用ctrl+d，写完可以用vim检查一下)</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># mkdir /opt/data</span></span><br><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># cat &gt; /opt/data/wc.input</span></span><br><span class="line">hadoop mapreduce hive</span><br><span class="line">hbase spark storm</span><br><span class="line">sqoop hadoop hive</span><br><span class="line">spark hadoop</span><br></pre></td></tr></table></figure>

<h5 id="2、运行hadoop自带的mapreduce-Demo"><a href="#2、运行hadoop自带的mapreduce-Demo" class="headerlink" title="2、运行hadoop自带的mapreduce Demo"></a>2、运行hadoop自带的mapreduce Demo</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 Desktop]<span class="comment"># cd /opt/modules/hadoopstandalone/hadoop-2.5.0/</span></span><br><span class="line">[root@bigdata-senior01 hadoop-2.5.0]<span class="comment"># bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar  wordcount  /opt/data/wc.input  output2</span></span><br></pre></td></tr></table></figure>
<img src="/css/images/hadoop环境搭建1/11-job.png">
这里可以看到job ID中有local字样，说明是运行在本地模式下的。

<h5 id="3、查看输出文件"><a href="#3、查看输出文件" class="headerlink" title="3、查看输出文件"></a>3、查看输出文件</h5><p>本地模式下，mapreduce的输出是输出到本地。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-senior01 hadoop-2.5.0]<span class="comment"># ll output2</span></span><br><span class="line">total 4</span><br><span class="line">-rw-r--r-- 1 root root 60 oct 25 23:42 part-r-00000</span><br><span class="line">-rw-r--r-- 1 root root 0   oct 25 23:42 _SUCCESS</span><br></pre></td></tr></table></figure>

<p>输出目录中有_SUCCESS文件说明JOB运行成功，part-r-00000是输出结果文件。  </p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/1008/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
</article>






  
    <article id="post-9299-hadoop_log汇总" class="post-9299-hadoop_log汇总 post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/categories/hadoop/9299/">Hadoop_Error汇总</a>
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://wpblog.top/categories/hadoop/9299/" data-id="ckc4ip28c000piwtva7ps2pmn" class="leave-reply bdsharebuttonbox" data-cmd="more"></a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h3 id="一-namenode"><a href="#一-namenode" class="headerlink" title="一. namenode"></a>一. namenode</h3><h3 id="二-datanode"><a href="#二-datanode" class="headerlink" title="二. datanode"></a>二. datanode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec <span class="built_in">set</span> to value below 1 ms/sec. Assuming default value of 1000</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.directoryscan.throttle.limit.ms.per.sec&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: node1:50010:DataXceiver error processing READ_BLOCK operation  src: /192.168.100.1:15519 dst: /192.168.100.20:50010</span><br><span class="line">INFO org.apache.hadoop.hdfs.server.datanode.DataNode: node1:50010:DataXceiver error processing WRITE_BLOCK operation  src: /192.168.100.22:52452 dst: /192.168.100.20:50010; </span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;8192&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">cat /etc/security/limits.conf</span><br></pre></td></tr></table></figure>



      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/categories/hadoop/9299/">
    <time datetime="2019-10-21T16:04:18.000Z" class="entry-date">
        2019-10-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">读书笔记</a></li></ul>

    </footer>
</article>






  
  
    <nav id="pagination">
      <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
      </nav>
    </nav>
  

</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  
    
  <aside class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">6</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-content">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">读书笔记</a><span class="tag-list-count">5</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">最近更新</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/categories/hadoop/9200/">hadoop生态</a>
          </li>
        
          <li>
            <a href="/categories/hadoop/1006/">Hadoop环境搭建-首页</a>
          </li>
        
          <li>
            <a href="/categories/hadoop/1010/">Hadoop环境搭建-第四部分 完全分布式模式安装</a>
          </li>
        
          <li>
            <a href="/categories/linux/9001/">第一章：部署虚拟环境安装linux系统</a>
          </li>
        
          <li>
            <a href="/categories/hadoop/1011/">Hadoop环境搭建-第五部分 Hadoop HA安装</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <h4>博客技术架构</h4>
    <ul type="disc">
           <li>&nbsp;&nbsp;托管平台：<a href="https://dev.tencent.com/" target="_blank">腾讯云开发者平台</a>&<a href="http://www.github.com" target="_blank">Github</a></li>
           <li>&nbsp;&nbsp;博客框架：<a href="http://hexo.io/" target="_blank">Hexo</a></li>
    </ul>
    <br/>
    <p>&copy; 2020 王鹏
    All rights reserved.</p>
</footer>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/js/share.js'];</script>

<script src="/js/jquery-3.3.1.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div>
</body>
</html>